# 算法和数据结构

## 数据结构

### 数组

内存中一块连续的存储空间

时间复杂度: 查询 O(1)  插入/删除 O(n)

#### 链表

插入/删除O(1)  查询O(n)

##### 反转链表

```go
func reverseList(head *ListNode) *ListNode {
    cur := head
    var pre *ListNode
    for cur!=nil {
        next := cur.Next
        cur.Next = pre
        pre = cur
        cur = next
    }
    return pre
}
```



##### 判断是否有环

```go
func hasCycle(head *ListNode) bool {
    slow:=head
    if  head ==nil || head.Next==nil{
        return false
    }
    fast:=head.Next.Next
    
    for fast !=nil && fast.Next!=nil{
        slow = slow.Next
        fast = fast.Next.Next
        if fast ==slow{
            return true
        }
    }
    return false
}
```

##### 两两交换节点 

```go
// https://leetcode-cn.com/problems/swap-nodes-in-pairs/
func swapPairs(head *ListNode) *ListNode {
   dumy := &ListNode{
       0,
       head,
       }
   tmp :=dumy

   for tmp.Next !=nil && tmp.Next.Next!=nil {
       node1 := tmp.Next             // 1
       node2 := tmp.Next.Next        // 2

       tmp.Next = node2  

       node1.Next = node2.Next // 1->3
       node2.Next = node1      // 2->1

       tmp = node1
   }
    return dumy.Next
}

```



## 1.斐波那契数列 

```go
// //斐波那契数列1，1，2，3，5，8，13  (前两数相加等于后一个数)
func f(n int) int {
	if n >= 2 {
		return f(n-1) + f(n-2)
	}
	return 1
}
```



## 2.冒泡排序

```go
func main() {
	list := []int{11, 22, 21, 33, 44, 34}
	for j := 0; j < len(list); j++ {
		for i := 0; i < len(list)-j; i++ {
			if i+1 < len(list) && list[i] > list[i+1] {
				list[i], list[i+1] = list[i+1], list[i]
			}
		}
	}
}
```

## 3.快速排序

```go
func quickSort(list []int) (newList []int) {
	i := len(list)
	if i < 1 {
		return list
	}
	left, right := []int{}, []int{}
	for index, value := range list {
		if index == i-1 {
			continue
		}
		if value < list[i-1] {
			left = append(left, value)

		} else {
			right = append(right, value)
		}
	}
	left = quickSort(left)
	right = quickSort(right)
	newList = append(newList, left...)
	newList = append(newList, list[i-1])
	newList = append(newList, right...)
	return newList
}
```





## 4.插入排序

```php
// 如何理解插入排序 https://zhuanlan.zhihu.com/p/134590892
function insertionSort(&$arr)
{
    $n = count($arr);
    if ($n < 2) {
        return $n;
    }
    for ($i = 1; $i < $n; $i++) {
        $value = $arr[$i]; // 本次要插入的数
        $j = $i - 1; // 在有序区的数字个数
        for (; $j >= 0; $j--) {
            // 如果有序区的数字比要插入的大，那么就往后挪一位，给要插入的数字留空间
            if ($arr[$j] > $value) {
                $arr[$j + 1] = $arr[$j];
            } else {
                break;
            }
        }

        // 插入 因为循环多减了1 所以这里要加1
        $arr[$j + 1] = $value;
    }
}
```

## 5.选择排序

```go
// 计算最小值
func sort(list []int) []int {
	for i := 0; i < len(list); i++ {
		// 假设第一个为最小值
		key, min := i, list[i]
		// 计算后面最小的索引和值
		for index, value := range list[i:] {
			if value < min {
				// 最小值
				min = value
				// 最小值的实际key
				key = index + i
			}
		}
		// 交换最小值 与位次
		list[i], list[key] = min, list[i]
	}
	return list
}
```

## 6.判断是否存在重复

### 	6.1双循环

​	执行用时：700 ms, 在所有 Go 提交中击败了5.18%的用户

​	内存消耗：6 MB, 在所有 Go 提交中击败了98.07%的用户

```go
func containsDuplicate(nums []int) (flag bool) {
	flag = false
	for i := 0; i < len(nums); i++ {
		for _, value := range nums[i+1:] {
			if nums[i] == value {
				return true
			}
		}
	}
	return
}
```

### 	6.2借助map

​	执行用时：24 ms, 在所有 Go 提交中击败了74.95%的用户

​	内存消耗：7.7 MB, 在所有 Go 提交中击败了53.21%的用户

```go
func containsDuplicate(nums []int) (flag bool) {
	m := map[int]int{}
	for _, value := range nums {
		if _, ok := m[value]; ok {
			return true
		}
		m[value]++
	}
	return
}
```

### 6.3先排序

​	执行用时：28 ms, 在所有 Go 提交中击败了28.96%的用户

​	内存消耗：6 MB, 在所有 Go 提交中击败了88.44%的用户

```go
func containsDuplicate(nums []int) bool {
    sort.Ints(nums)
    for i := 1; i < len(nums); i++ {
        if nums[i] == nums[i-1] {
            return true
        }
    }
    return false
}

```

## 7.求两数的和

### 7.1暴力枚举

执行用时：4 ms, 在所有 Go 提交中击败了95.69%的用户

内存消耗：3 MB, 在所有 Go 提交中击败了78.41%的用户

```go
func twoSum(nums []int, target int) []int {

	for index, value := range nums {
		for i, v := range nums[index+1:] {
			if target-value == v {
        return []int(index,index + 1 + i)
			}
		}
	}
	return continer
}

```

### 7.2借助map

执行用时：4 ms, 在所有 Go 提交中击败了95.69%的用户

内存消耗：3 MB, 在所有 Go 提交中击败了78.41%的用户

```go
func twoSum(nums []int, target int) []int {
	var m = map[int]int{}
	for index, value := range nums {
		if _, ok := m[target-value]; ok {
			return []int{m[target-value], index}
		}
		m[value] = index
	}
	return nil
}
```

## 8.二分法查找

> 概述

二分法查找简历在排序的基础上

> 思路

找到中间元素下标

重复比较要查找的元素与中间元素，判断被查找元素在左侧还是右侧

直到中间的元素是被查找的元素

```java

public static int search(int start,int end,int target,int a[]){
        if(start <= end) {
            int mid = (start + end) / 2;
            if (a[mid] == target) {
                return mid;
            } else if (target > a[mid]) {
                //target >和=都判断过了a[mid] 那么下次开始的位置应该越过mid的后一个位置
                return search(mid + 1, end, target, a);
            } else if (target < a[mid]) {
                //target <和=都判断过了a[mid] 那么下次结束的位置应该越过end到mid的前一个位置
                return search(start, mid - 1, target, a);
            }
        }
 
        return -1;
    }
```

```php
function search($nums, $target)
{
    $l = count($nums);
    if ($l < 1) {
        return $nums;
    }
    $start = 0;
    $end = $l;
    $flag = true;
    while ($flag) {
        $k = $start + ($end - $start) / 2;
        if ($nums[$k] == $target) {
            return $k;
        } else if ($nums[$k] < $target) {
            $start = $k+1;
        }else{
            $end = $k-1;
        }
    }
}
```



## 9.求阶乘

```php
// 请用递归实现一个阶乘求值算法 F(n): n=5;F(n)=5!=5*4*3*2*1=120
function F($n){    
 if($n==0){         
 		return 1;      
 }else{         
 		return $n* F($n-1);      
 	}
}
```


## 10.将下划线转驼峰 

将字符长fang-zhi-gang 转化为驼峰法的形式：FangZhiGang

```php
function Fun($str){  

 $arr1=explode('_',$str);   

 $str = implode(' ',$arr1);   

 return str_replace(' ','',ucwords($str)) ;

 }

```

## 10.求最长不重复子串长度

```php
 function lengthOfLongestSubstring($s)
{
    $l = strlen($s);
    $max = 0;
    for ($i = 0; $i < $l; $i++) {
        // 每一轮要重置数组
        $array = [];
        for ($j = $i; $j < $l; $j++) {
            // 如果已经包含了，说明有重复的了
            if (in_array($s{$j}, $array)) {
                break;
            }
            // 没有重复，往数组里加
            $array[] = $s{$j};
            if (count($array) > $max) {
                $max = count($array);
            }
        }
    }
    return $max;
}
```

## 11.判断是否是回文

```go
func f(s string) (b bool) {
	list := []rune(s)
	l := len(list)
	for index := range s {
		if s[index] != s[l-1-index] {
			return false
		}
	}
	return true
}
```

```php
function isPalindrome($x)
{
    if ($x == strrev($x)) {
        return true;
    }
    return false;
}
```

## 

# PHP

## 1.基本语法

### 魔术方法

```php
1. __construct 具有构造函数的类会在每次创建新对象时先调用此方法;初始化工作执行。
2. __desstruct 对象的所有引用都被删除或者当对象被显式销毁时执行。
3.__call()在对象中调用一个不可访问方法时，__call() 会被调用。
4.__callStatic()在静态上下文中调用一个不可访问方法时，__callStatic() 会被调用。
5.__set() 在给不可访问的属性赋值时调用
6.__get() 读取不可访问的属性值是自动调用
7.__isset() 当对不可访问的私有属性使用isset或empty时自动调用
8.__unset() 当对不可访问的私有属性使用unset时；自动调用
9.__toString()当一个类的实例对象；被当成一个字符串输出时调用
```

### 数组函数

```php
array_combine()----通过合并两个数组来创建一个新数组

range()----创建并返回一个包含指定范围的元素的数组

compact()----建立一个数组

array_chunk()----将一个数组分割成多个

array_merge()----把两个或多个数组合并成一个数组

array_slice()----在数组中根据条件取出一段值

array_diff()----返回两个数组的差集数组

array_intersect()----计算数组的交集

array_search()----在数组中搜索给定的值

array_splice()----移除数组的一部分且替代它

array_key_exists()----判断某个数组中是否存在指定的key

shuffle()----把数组中的元素按随机顺序重新排列

array_flip()----交换数组中的键和值

array_reverse()----将原数组中的元素顺序翻转，创建新的数组并返回

array_unique()----移除数组中重复的值
```

### 面试题

> PHP的isset和is_array哪个快?

isset() 是比较快的。

显而易见，isset()仅测试单个值。而in_array()将遍历整个数组，测试每个元素的值。

> php autoload和spl_autoload区别?

spl_autoload 支持自定义的类加载方式，更加灵活

```php

<?php
 function __autoload($classname){
 $classpath="./".$classname.'.php';
 if(file_exists($classpath)){
  require_once($classpath);
 }
 else{
  echo 'class file'.$classpath.'not found!';
 }
}
$newobj = new ClassA();
$newobj = new ClassB();
?>
  
<?php
function loadprint( $class ) {
 $file = $class . '.class.php';
 if (is_file($file)) {
  require_once($file);
 }
}
spl_autoload_register( 'loadprint' );
$obj = new PRINTIT();
$obj->doPrint();
?>  
```

> PHP-FPM 的三种模式?

1）pm=static
　　始终保持固定数量的worker进程数，由pm.max_children决定，不会动态扩容。

　　配置项要求

　　1、pm.max_children> 0 必须配置，且只有这一个参数生效

　　优缺点

　　如果配置成static，只需要考虑max_children的数量，数量取决于cpu的个数和应用的响应时间，

（2）pm=dynamic

　　php-fpm启动时，会初始启动一些worker，初始启动worker数决定于pm.max_children的值。在运行过程中动态调整worker数量，worker的数量受限于pm.max_children配置，同时受限全局配置process.max。
　　1秒定时器作用，检查空闲worker数量，按照一定策略动态调整worker数量，增加或减少。增加时，worker最大数量<=max_children· <=全局process.max；减少时，只有idle >pm.max_spare_servers时才会关闭一个空闲worker。

　　优缺点
　　优点：动态扩容，不浪费系统资源
　　缺点：如果所有worker都在工作，新的请求到来只能等待master在1秒定时器内再新建一个worker，这时可能最长等待1s


（3）pm=ondemand

　　php-fpm启动的时候，不会启动任何一个worker，而是按需启动，只有当连接过来的时候才会启动。
　　启动的最大worker数决定于pm.max_children的值，同时受限全局配置process.max。
　　1秒定时器作用，如果空闲worker时间超过pm.process_idle_timeout的值（默认值为10s），则关闭该worker。这个机制可能会关闭所有的worker。

　　优缺点
　　优点：按流量需求创建，不浪费系统资源
　　缺点：由于php-fpm是短连接的，所以每次请求都会先建立连接，频繁的创建worker会浪费系统开销。，所以，在大流量的系统上，master进程会变得繁忙，占用系统cpu资源，不适合大流量环境的部署。

> cgi、fast-cgi、php-fpm各自的含义

Cgi 就是一个**协议**，规范了应用程序与web服务器（Apache、nginx）的通讯。

fast-cgi 是Cgi升级版

"php-fpm" 是对 "fastcgi"协议的具体实现是一个应用程序。

> select模型和epoll模型的区别

|     指标     |                            select                            |                            epoll                             |
| :----------: | :----------------------------------------------------------: | :----------------------------------------------------------: |
|     性能     | 随着连接数的增加性能急剧下降。处理成千上万并发连接时，性能很差 | 随着连接数的增加，性能基本上没有下降。处理成千上万并发连接时，性能很好 |
|    连接数    | 连接数有限制，处理的最大连接数不超过 1024 个 。如果超过 1024 个则需修改 FD_SETSIZE 宏，并重新编译 |                         连接数无限制                         |
| 内在处理机制 |                           线性轮询                           |                        回调 callback                         |
|  开发复杂性  |                              低                              |                              中                              |



## 2.框架

### 2.1TP

### 2.2Laravel

## 3.PHP8区别

### **PHP 8新特性**

#### 命名参数

#### 注解（Attributes）

#### 构造器属性提升

PHP8构造器属性提升的用法，这个特性对于一些需要在构造器中设置或初始化一些类属性的时候非常有用（包括`public`、`protected`和`private`），比如在PHP7中你可以这样定义一个类的属性，然后在构造方法中传值。

> Php 7

```php
class Point
{
    public int $x;
    private string $y;

    public function __construct(int $x = 0, string $y = '')
    {
        $this->x = $x;
        $this->y = $y;
    }
}
```

> Php 8

```php
class Point
{
    public function __construct(public int $x = 0, private string $y = ''){
        
// 你可以在构造器中直接输出类的x和y属性的值（也就是传入的x和y变量的值）

    }
}
```

#### Union types：联合类型

```php
public function foo(Foo|Bar $input): int|float;
```

#### Match 表达式

```php
// 类似switch
<?php
$return_value = match (subject_expression) {
    single_conditional_expression => return_expression,
    conditional_expression1, conditional_expression2 => return_expression,
};
?>
```

#### JIT (Just In Time)

如果说 Opcache 扩展可以更快的获取 Opcodes 将其直接转到 Zend VM，则 JIT 让它们完全不使用 Zend VM 即可运行。

Zend VM 是用 C 编写的程序，充当 Opcodes 和 CPU 之间的一层。 JIT 在运行时直接生成编译后的代码，因此 PHP 可以

跳过 Zend VM 并直接被 CPU 执行。

### PHP7 新特性

#### 标量类型

```php
<?php
// Coercive mode
function sumOfInts(int ...$ints)
{
    return array_sum($ints);
}

var_dump(sumOfInts(2, '3', 4.1));
```

#### 返回值类型声明

```php
<?php

function arraysSum(array ...$arrays): array
{
    return array_map(function(array $array): int {
        return array_sum($array);
    }, $arrays);
}

print_r(arraysSum([1,2,3], [4,5,6], [7,8,9]));
```

#### 新增？？

```php
$username = $_GET['user'] ?? 'nobody';
```

#### 通过 [define()](https://www.php.net/manual/zh/function.define.php) 定义常量数组 

```php
<?php
define('ANIMALS', [
    'dog',
    'cat',
    'bird'
]);

echo ANIMALS[1]; // 输出 "cat"
?>
```



# MYSQL

### 基础架构

![img](https://static001.geekbang.org/resource/image/0d/d9/0d2070e8f84c4801adbfa03bda1f98d9.png)

#### 连接器

负责跟客户端建立连接、获取权限、维持和管理连接。

##### 链接命令

```mysq
mysql -h$ip -P$port -u$user -p
```

查看链接命令

```
show processlist
```

#### 查询缓存(MySQL 8.0版本已删除)

#### 分析器

分析器会做“词法分析”。你输入的是由多个字符串和空格组成的一条SQL语句，MySQL需要识别出里面的字符串分别是什么，代表什么。

#### 优化器

优化器是在表里面有多个索引的时候，决定使用哪个索引；或者在一个语句有多表关联（join）的时候，决定各个表的连接顺序。

#### 执行器

### 日志

#### 重要的日志模块：redo log

redo log是InnoDB引擎特有的日志

当有一条记录需要更新的时候，InnoDB引擎就会先把记录写到redo log（粉板）里面，并更新内存，这个时候更新就算完成了。同时，InnoDB引擎会在适当的时候，将这个操作记录更新到磁盘里面，而这个更新往往是在系统比较空闲的时候做，这就像打烊以后掌柜做的事。

#### 重要的日志模块：binlog

server层日志系统

### 异同

1. redo log是InnoDB引擎特有的；binlog是MySQL的Server层实现的，所有引擎都可以使用。
2. redo log是物理日志，记录的是“在某个数据页上做了什么修改”；binlog是逻辑日志，记录的是这个语句的原始逻辑，比如“给ID=2这一行的c字段加1 ”。
3. redo log是循环写的，空间固定会用完；binlog是可以追加写入的。“追加写”是指binlog文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。

## 事务

### 什么是事务？

事务就是要保证一组数据库操作，要么全部成功，要么全部失败。在MySQL中，事务支持是在引擎层实现的。

事务是由一组sql语句组成的逻辑处理单元，事务有4个特性，通常简称为ACID

### 事务的四个特性

- 原子性：事务是一个原子操作单元，其对数据的修改，要么全都执行，要么全都不执行。
- 一致性：在事务开始和完成时，数据都必须保持一致状态。这意味着所有相关的数据规则都必须应用于事务的修改，以保持数据的完整性。事务结束时，所有的内部数据结构，也都必须正确。
- 隔离性：数据库系统提供一定的隔离机制，保证事务在不受外部并发操作影响的”独立“环境执行。这意味着事务处理过程中的中间状态对外部是不可见的。
- 持久性：事务完成之后，它对数据的修改是永久性的。即使出现系统故障也能够保持。 

###  并发事务带来的问题

- 更新丢失:后提交的事务覆盖了先提交的事务。

- 赃读：事务A读取到了事务B已修改但未提交的数据，如果事务B回滚，A读取的数据无效，不符合一致性要求。

- 不可重复读：再次读取以前读过的数据，返回数据不一致。（其他事务在期间修改或删除了该数据）

- 幻读：再次读取以前读过的数据，返回数据不一致。（其他事务在期间新增了数据）

  以上都是数据库读一致性的问题，必须由数据库提供一定的事务隔离机制来解决。

### 事务的隔离级别

| 隔离级别 | 读数据一致性                                                 | 赃读 | 不可重复度 | 幻读 |
| -------- | ------------------------------------------------------------ | ---- | ---------- | ---- |
| 读未提交 | 一个事务还没提交时，它做的变更就能被别的事务看到             | 是   | 是         | 是   |
| 读已提交 | 一个事务提交之后，它做的变更才会被其他事务看到               | 否   | 是         | 是   |
| 可重复读 | 一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一致的。当然在可重复读隔离级别下，未提交变更对其他事务也是不可见的 | 否   | 否         | 是   |
| 可序列化 | 顾名思义是对于同一行记录，“写”会加“写锁”，“读”会加“读锁”。当出现读写锁冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行 | 否   | 否         | 否   |



## 锁

### 全局锁

顾名思义，全局锁就是对整个数据库实例加锁。MySQL提供了一个加全局读锁的方法，命令是 Flush tables with read lock (FTWRL)。当你需要让整个库处于只读状态的时候，可以使用这个命令，之后其他线程的以下语句会被阻塞：数据更新语句（数据的增删改）、数据定义语句（包括建表、修改表结构等）和更新类事务的提交语句。

**全局锁的典型使用场景是，做全库逻辑备份。**也就是把整库每个表都select出来存成文本。

### 表级锁

##### 表锁

**表锁的语法是 lock tables … read/write。**与FTWRL类似，可以用unlock tables主动释放锁，也可以在客户端断开的时候自动释放。需要注意，lock tables语法除了会限制别的线程的读写外，也限定了本线程接下来的操作对象。

举个例子, 如果在某个线程A中执行lock tables t1 read, t2 write; 这个语句，则其他线程写t1、读写t2的语句都会被阻塞。同时，线程A在执行unlock tables之前，也只能执行读t1、读写t2的操作。连写t1都不允许，自然也不能访问其他表。

#### 元数据锁（meta data lock，MDL，针对的是表结构)

当对一个表做增删改查操作的时候，加MDL读锁；当要对表做结构变更操作的时候，加MDL写锁。

- 读锁之间不互斥，因此你可以有多个线程同时对一张表增删改查。
- 读写锁之间、写锁之间是互斥的，用来保证变更表结构操作的安全性。因此，如果有两个线程要同时给一个表加字段，其中一个要等另一个执行完才能开始执行

###### 如何安全地给小表加字段？

比较理想的机制是，在alter table语句里面设定等待时间，如果在这个指定的等待时间里面能够拿到MDL写锁最好，拿不到也不要阻塞后面的业务语句，先放弃。之后开发人员或者DBA再通过重试命令重复这个过程。

### 行锁

行锁就是针对数据表中行记录的锁。这很好理解，比如事务A更新了一行，而这时候事务B也要更新同一行，则必须等事务A的操作完成后才能进行更新。

**在InnoDB事务中，行锁是在需要的时候才加上的，但并不是不需要了就立刻释放，而是要等到事务结束时才释放。这个就是两阶段锁协议。**

#### 死锁和死锁检测

当并发系统中不同线程出现循环资源依赖，涉及的线程都在等待别的线程释放资源时，就会导致这几个线程都进入无限等待的状态，称为死锁。这里我用数据库中的行锁举个例子。
![img](https://static001.geekbang.org/resource/image/4d/52/4d0eeec7b136371b79248a0aed005a52.jpg)

这时候，事务A在等待事务B释放id=2的行锁，而事务B在等待事务A释放id=1的行锁。 事务A和事务B在互相等待对方的资源释放，就是进入了死锁状态。当出现死锁以后，有两种策略：

- 一种策略是，直接进入等待，直到超时。这个超时时间可以通过参数innodb_lock_wait_timeout来设置。
- 另一种策略是，发起死锁检测，发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。将参数innodb_deadlock_detect设置为on，表示开启这个逻辑。

## 2索引

### 2.0什么是索引

索引是帮助mysql高效获取数据的数据结构。**索引的本质是数据结构。**索引的目的在于提高查询效率，可以类比字典。

**可以理解为“排好序的快速查找数据结构”**

### 2.1创建索引

#### 2.1.1创建单个索引

```mysql
create (unique) index idx_user_name on user(name)
```

#### 2.1.2创建复合索引

```mysql
create (unique) index idx_user_nameEmail on user(name,email)
```

#### 2.1.3 删除索引

```mysql
drop index indexName on tableName
```

#### 2.1.4 查看索引

```mysql
show index form on tableName
```

#### 2.1.5 创建索引技巧

两表连接，左连接，右边表建索引，右连接左边表建索引。

### 2.2 哪些情况下需要建索引

1. 主键自动创建唯一索引
2. 频繁作为查询条件的字段应该创建索引 
3. 查询中与其他表关键字段，外键关系应该创建索引
4. 频繁更新的字段，不适合创建索引
5.  where 条件里用不到的，不需要建索引
6. 查询中排序字段，排序字段如果通过索引去访问，会大大提高查询速度
7.  查询中统计或者分组的字段

### 2.3哪些情况下不适合建索引

1. 表记录过少
2. 经常增删改的表
3. 某个列包含许多重复数据

### 2.4 主键，外键，索引，唯一索引

```text
主键(primary key) 能够唯一标识表中某一行的属性或属性组。一个表只能有一个主键，但可以有多个候选索引。主键常常与外键构成参照完整性约束，防止出现数据不一致。主键可以保证记录的唯一和主键域非空,数据库管理系统对于主键自动生成唯一索引，所以主键也是一个特殊的索引。


外键（foreign key） 是用于建立和加强两个表数据之间的链接的一列或多列。外键约束主要用来维护两个表之间数据的一致性。简言之，表的外键就是另一表的主键，外键将两表联系起来。一般情况下，要删除一张表中的主键必须首先要确保其它表中的没有相同外键（即该表中的主键没有一个外键和它相关联）。


索引(index) 是用来快速地寻找那些具有特定值的记录。主要是为了检索的方便，是为了加快访问速度， 按一定的规则创建的，一般起到排序作用。所谓唯一性索引，这种索引和前面的“普通索引”基本相同，但有一个区别：索引列的所有值都只能出现一次，即必须唯一。

总结：

主键一定是唯一性索引，唯一性索引并不一定就是主键。

一个表中可以有多个唯一性索引，但只能有一个主键。

主键列不允许空值，而唯一性索引列允许空值。

主键可以被其他字段作外键引用，而索引不能作为外键引用。
```

### 2.5 B树和B+树的区别

B+树只有叶子节点存储data，叶子节点包含了这棵树的所有键值，每个叶子节点有指向相邻叶子节点的指针，这样一棵树成了数据库系统实现索引的首选数据结构。 

### 2.6 InnoDB 的索引模型

假设，我们有一个主键列为ID的表，表中有字段k，并且在k上有索引。

![img](https://static001.geekbang.org/resource/image/dc/8d/dcda101051f28502bd5c4402b292e38d.png)

主键索引的叶子节点存的是整行数据。在InnoDB里，主键索引也被称为聚簇索引（clustered index）。

非主键索引的叶子节点内容是主键的值。在InnoDB里，非主键索引也被称为二级索引（secondary index）。

根据上面的索引结构说明，我们来讨论一个问题：**基于主键索引和普通索引的查询有什么区别？**

- 如果语句是select * from T where ID=500，即主键查询方式，则只需要搜索ID这棵B+树；
- 如果语句是select * from T where k=5，即普通索引查询方式，则需要先搜索k索引树，得到ID的值为500，再到ID索引树搜索一次。这个过程称为回表。

也就是说，基于非主键索引的查询需要多扫描一棵索引树。因此，我们在应用中应该尽量使用主键查询。

### 2.7索引选择异常和处理

采用force index强行选择一个索引

引导MySQL使用我们期望的索引

在有些场景下，我们可以新建一个更合适的索引，来提供给优化器做选择，或删掉误用的索引。

### 2.8 要给字符串创建前缀索引时，有什么方法能够确定我应该使用多长的前缀呢？

在建立索引时关注的是区分度，区分度越高越好。因为区分度越高，意味着重复的键值越少。因此，我们可以通过统计索引上有多少个不同的值来判断要使用多长的前缀。

首先，你可以使用下面这个语句，算出这个列上有多少个不同的值：

```
mysql> select count(distinct email) as L from SUser;
```

然后，依次选取不同长度的前缀来看这个值，比如我们要看一下4~7个字节的前缀索引，可以用这个语句：

```
mysql> select 
  count(distinct left(email,4)）as L4,
  count(distinct left(email,5)）as L5,
  count(distinct left(email,6)）as L6,
  count(distinct left(email,7)）as L7,
from SUser;
```

当然，使用前缀索引很可能会损失区分度，所以你需要预先设定一个可以接受的损失比例，比如5%。然后，在返回的L4~L7中，找出不小于 L * 95%的值，假设这里L6、L7都满足，你就可以选择前缀长度为6。

### 2.9 哪些情况下，索引会失效？

1. 索引字段上使用函数
2. like 以%开头，索引无效
3. 组合索引，不是使用第一列索引，索引失效。
4. 数据类型出现隐式转化。如varchar不加单引号的话可能会自动转换为int型，使索引无效，产生全表扫描。
5. 在索引字段上使用not，<>，!=。不等于操作符是永远不会用到索引的，因此对它的处理只会产生全表扫描。 优化方法： key<>0 改为 key>0 or key<0。
6. 当全表扫描速度比索引速度快时，mysql会使用全表扫描，此时索引失效。

## 3性能分析

#### 3.1Explain

##### 是什么？

使用explain关键字可以模拟优化器执行sql语句，从而知道mysql是如何处理sql语句的。可以分析查询语句或表结构的性能瓶颈

##### 各字段含义

```mysql
+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+-------+
| id | select_type | table | partitions | type | possible_keys | key  | key_len | ref  | rows | filtered | Extra |
+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+-------+
|  1 | SIMPLE      | ad    | NULL       | ALL  | NULL          | NULL | NULL    | NULL |    6 |   100.00 | NULL  |
+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+-------+
```

###### id

Select查询的序列号，表示查询中执行select子句或操作表的顺序，有三种情况

1. id相同：执行顺序由上自下
2. id不同：如果是子查询，id序列号会增大，id值越大优先级越高，会被先执行
3. id相同和不同同时存在：id大的先执行，其他的由上自下执行

###### select_type

- SIMPLE：简单的select查询，查询中不包含子查询作者union
- PRIMARY:查询中若包含复杂的子部分，那么最外层的查询会被标记为“PRIMARY”
- SUBQUERY:在select或where中包含了子查询
- DERIVED:在from列表中包含的子查询会被标记为“DERIVED”（衍生表，临时表），mysql会递归执行这些查询子句，把结果放在临时表里
- UNION:若第二个select出现在UNION之后，则被标记为UNION；若UNION包含在from子句的子查询中，外层select将为标记为DERIVED
- UNION RESULT：从UNION表中获取结果的select

###### Type

访问类型，显示查询使用了那种类型

- System:表中只有一行记录（等同于系统表），这是const类型的特例，平时不会出现。
- const:表示通过索引一次就找到了结果，const用于比较primary key 或者 unique索引。因为只匹配一行数据，所以很快。如果将主键放在where中，mysql就能将该查询转换为一个常量。
- eq_ref:唯一性索引扫描，对于每个索引键，表中只有一条记录与之匹配。常用于主键或唯一索引扫描。

> 简单地说是`const`是直接按主键或唯一键读取，`eq_ref`用于联表查询的情况，按联表的主键或唯一键联合查询。

- ​	ref:非唯一性索引扫描，返回匹配某个单独值的所有行。本质上也是一种索引访问，它返回所有匹配某个单独值的行。它可能会找到多个符合条件的行。是查找与扫描的混合体。
- Range:值检索指定范围内的行，使用一个索引来选择行。key列显示使用了哪个索引。一般就是在where语句中出现了"between,<,>,in"等查询。这种范围查询扫描索引扫描比全表扫描要好，因为它只需要开始于索引的某一点，结束于另一点，不用扫描全部索引。 
- Index:全索引扫描，与all的区别是，all为index类型，只遍历索引树。通常比all快，因为索引文件通常比数据文件小。也就是说虽然index与all都是读全表，但是index是从索引中读取的，而all是从硬盘中读取的。
- all 全表扫描，将遍历全表以找到匹配的行，是最慢的



**从最好到最差，依次是**

**system>const>eq_ref>ref>range>index>all**

###### Possible_keys

显示可能应用到这张表中的索引，一个或多个。查询涉及到的字段若存在索引，则该索引将被列出，**但不一定被查询实际使用**

######  Key

实际使用的索引。如果为null，则没有使用索引。如果查询中使用了覆盖索引，则该索引仅仅出现在key列表中

###### Key_len

表示索引中使用的字节数。key_len显示的值是索引字段的最大可能长度，并非实际使用长度。个人理解是，查询可能使用索引的最大长度。 

###### ref

显示了索引的哪个列被使用了。哪些列或常量被用于查找索引列上的值。

###### Rows

根据表统计信息及索引选用情况，大致估算出找到列所要扫描的行数。

###### Extra

十分重要的额外信息

**using filesort:**说明mysql会对数据使用一个外部的索引排序，而不是按照表内的索引顺序进行读取。mysql中无法利用索引完成的操作成为文件排序。尽量优化。

**Using temporary**:使用了临时表保存中间结果，mysql在对查询结果排序时使用临时表。长用于排序和分组查询。必须优化。

**Using index**:表示响应的select操作中使用了覆盖索引，避免访问了表的数据行，效率高。

如果同时出现using where ,表示索引被用来执行索引键值的查找。

如果没有出现using where,表示索引用来读取数据而非执行查找动作。

**Using where**:表示使用了where过滤

**Using join buffer**:表示使用了连接缓存

**impossible where**:where是无效的，where的值总是false。

### 4 最佳实践

最好是全值匹配

最佳左前缀法则

不在索引列上做任何操作（计算、函数、类型转换），会导致索引失效

存储引擎不能使用索引中范围条件右边的列

尽量使用覆盖索引（访问索引的查询（索引列和查询列一致）），减少select*

mysql在使用比较符号时无法使用索引

is null,is not null 也无法使用索引

like以通配符开头（‘’%abc...“）

###  5.innodb和myisam区别

- innodb支持事务
- Innodb不支持全文索引
- MyISAM支持表级锁定，InnoDB支持行级锁
- InnoDB（索引组织表）使用的聚簇索引、索引就是数据，顺序存储，因此能缓存索引，也能缓存数据，MyISAM（堆组织表）使用的是非聚簇索引、索引和文件分开，随机存储，只能缓存索引

### **6.基于主键索引和普通索引的查询有什么区别？**

- 如果语句是select * from T where ID=500，即主键查询方式，则只需要搜索ID这棵B+树；
- 如果语句是select * from T where k=5，即普通索引查询方式，则需要先搜索k索引树，得到ID的值为500，再到ID索引树搜索一次。这个过程称为回表。

也就是说，基于非主键索引的查询需要多扫描一棵索引树。因此，我们在应用中应该尽量使用主键查询。

### 7.什么是回表？

回到主键索引树搜索的过程，我们称为回表

### 8.如何避免回表？

主键索引:使用主键查询方式，则只需要搜索ID这棵B+树；

覆盖索引：**由于覆盖索引可以减少树的搜索次数，显著提升查询性能，所以使用覆盖索引是一个常用的性能优化手段。**

9.什么是索引下推？

以市民表的联合索引（name, age）为例。如果现在有一个需求：检索出表中“名字第一个字是张，而且年龄是10岁的所有男孩”。那么，SQL语句是这么写的：

```mysql
mysql> select * from tuser where name like '张%' and age=10 and ismale=1;
```

根据最左前缀原则，只能用“张”查出对应Id，然后回表查询。索引下推就是根据索引中包含的值进行过滤（这里是AGE=10）,减少了回表次数。



## 分库分表

## 主从

### 复制的三个步骤

1. master将该表记录记录到二进制日志（binary log）。这些记录过程叫做二进制日志事件。
2. slave将mater的bin log拷贝到它的中继日志（relay log）
3. slave重做中继日志中的事件，将改变应用到自己的数据库中。mysql复制是异步且串行的

## 书籍



# REDIS

## 基础知识

- redis默认有16个数据库，默认使用第0个数据库。
- redis是单线程的

```shell
select 3 # 切换三号数据库
DBSIZE # 查看数据库大小
flushdb # 清空当前数据库
flushall # 清空所有数据库
```

### 数据类型

#### String

```bash
incr view # 自增1
decr view # 自减1
incrby view 10 # 自增10
decrby view 10 # 自减10

setex key 30 "value"		# 设置30秒过期的key,setex (set with expire)  设置过期时间
setnx key "value" # setnx (如果key不存在设置)  在分布式锁中常常使用 

mset k1 v1 k2 v2 k3 v3 # 同时设置多个值
mget k1 k2 k3 # 同时获取多个值
msetnx k1 v1 k4 v4 # 同时设置多个值，原子操作
getset key value # 先取值，再设置值

getrange key 0,3 # 截取字符串索引0，3的值 

```

#### List

```shell
lpush # 向左边插入一个数据
lpop  # 从左边移除一个值

rpush # 向右边插入一个值
rpop  # 从右边移除一个值

lrange # 获取list中的值
lindex # 通过下表获取list中的某个值
lrem   # 移除指定个数的值
ltrim  # 通过下表截取指定的长度，会改变list，只剩下截取的元素  
```

#### set

```shell
sadd  # 添加一个值
smembers # 查看集合中所有值
sismember # 判断是否是集合中的元素
scard # 获取集合中元素个数
srem # 移除集合中的一个元素
srandmember [key] [num] # 随机抽选出n个元素v 
smove [key1] [key2] [value] # 将一个指定的值，移动到另外一个集合中
sdiff [key1] [key2] # 比较两个集合中不同的值
sinter [key1] [key2] # 取两个集合的交集 
sunion [key1] [key2] # 取两个集合的并集
```

hash

```shell
hset name key1 value1 # 设置一个值
hget name key1 # 取一个值
hmset name key1 value1  key2 value2  # 一个key 设置多个值
hmget name key1 key2 # 获取一个key多个值
hgetall key # 获取全部的数据
hdel name key1 # 删除key中的一个filed
hexists name key1 # 判断指定字段是否存在
hkeys name	# 取所有的key
hvals name # 取所有的值
incr name key1 # 自增
decr name key1 # 自减

```

#### Zset

```shell
zadd [key] [score] [value] # 添加一个值
zrangebyscore [key] [min] [max] # 按score排序
```

### 事务

**redis单条命令是保证原子性的，但事务是不保证原子性的，也没有事务隔离级别的概念。**

redis事务本事：一组命令的集合。一个事务中的所有命令都会被序列化，在事务执行过程中，会按照顺序执行。

- 一次性
- 顺序性
- 排他性

事务执行：

- 开启事务（multi）
- 命令入队 (...)
- 执行事务 (exec)|取消事务（discard）

### 内存淘汰策略

1. noeviction(默认策略)：对于写请求不再提供服务，直接返回错误（DEL请求和部分特殊请求除外）
2. allkeys-lru：从所有key中使用LRU算法进行淘汰
3. volatile-lru：从设置了过期时间的key中使用LRU算法进行淘汰
4. allkeys-random：从所有key中随机淘汰数据
5. volatile-random：从设置了过期时间的key中随机淘汰
6. volatile-ttl：在设置了过期时间的key中，根据key的过期时间进行淘汰，越早过期的越优先被淘汰

当使用volatile-lru、volatile-random、volatile-ttl这三种策略时，如果没有key可以被淘汰，则和noeviction一样返回错误

```shell
如何获取及设置内存淘汰策略 获取当前内存淘汰策略：
127.0.0.1:6379> config get maxmemory-policy

通过配置文件设置淘汰策略（修改redis.conf文件）：
maxmemory-policy allkeys-lru

通过命令修改淘汰策略：
127.0.0.1:6379> config set maxmemory-policy allkeys-lru
```

#### Lru实现

使用定长链表来保存所有缓存的值，并且最老的值放在链表最后面 当访问的值在链表中时： 将找到链表中值将其删除，并重新在链表头添加该值（保证链表中 数值的顺序是从新到旧） 当访问的值不在链表中时： 当链表已满：删除链表最后一个值，将要添加的值放在链表头 当链表未满：直接在链表头添加。



### redis实现乐观锁

- 悲观锁：认为什么时候都会出现问题，无论做什么都会加锁。

- 乐观锁：

  认为什么时候都不会出问题，所以不会加锁。更新数据的时候去判断一下，在此期间是否有人修改过数据。

  获取version

  更新的时候比较version

```shell
127.0.0.1:6379> set money 100
OK
127.0.0.1:6379> set out 0
OK
127.0.0.1:6379> watch money # 监视money 对应
OK
127.0.0.1:6379> multi 
OK
127.0.0.1:6379> decrby money 20
QUEUED
127.0.0.1:6379> incrby out 20
QUEUED
127.0.0.1:6379> exec # 事务正常结束，数据money期间没有发生变动，这个时候可以正常成功
1) (integer) 80
2) (integer) 20
==========================================================
127.0.0.1:6379> watch money
OK
127.0.0.1:6379> multi
OK
127.0.0.1:6379> decrby money 10
QUEUED
127.0.0.1:6379> incrby out 10
QUEUED
127.0.0.1:6379> exec # 其他事务修改了money,事务执行失败
(nil)
127.0.0.1:6379> unwatch  # 执行失败要释放
```

### Redis conf 详解

> 单位 

 配置文件 unit单位对大小写不敏感

```shell
# Redis configuration file example.
#
# Note that in order to read the configuration file, Redis must be
# started with the file path as first argument:
#
# ./redis-server /path/to/redis.conf

# Note on units: when memory size is needed, it is possible to specify
# it in the usual form of 1k 5GB 4M and so forth:
#
# 1k => 1000 bytes
# 1kb => 1024 bytes
# 1m => 1000000 bytes
# 1mb => 1024*1024 bytes
# 1g => 1000000000 bytes
# 1gb => 1024*1024*1024 bytes
#
# units are case insensitive so 1GB 1Gb 1gB are all the same.
```

> 包含

 ```shell
################################## INCLUDES ###################################

# Include one or more other config files here.  This is useful if you
# have a standard template that goes to all Redis servers but also need
# to customize a few per-server settings.  Include files can include
# other files, so use this wisely.
#
# Notice option "include" won't be rewritten by command "CONFIG REWRITE"
# from admin or Redis Sentinel. Since Redis always uses the last processed
# line as value of a configuration directive, you'd better put includes
# at the beginning of this file to avoid overwriting config change at runtime.
#
# If instead you are interested in using includes to override configuration
# options, it is better to use include as the last line.
#
# include /path/to/local.conf
# include /path/to/other.conf
 ```

> 网络

```shell
bind 127.0.0.1 # 绑定的ip
port 6379 # 端口
protected-mode yes # 保护模式 
#redis3.2版本后新增protected-mode配置，默认是yes，即开启。设置外部网络连接redis服务，设置方式如下：

#1、关闭protected-mode模式，此时外部网络可以直接访问

#2、开启protected-mode保护模式，需配置bind ip或者设置访问密码
```

> 通用

```shell
daemonize yes # 以守护进程方式运行

# 1、daemonize介绍
# A、redis.conf配置文件中daemonize守护线程，默认是NO。
# B、daemonize是用来指定redis是否要用守护线程的方式启动。

# 2、daemonize 设置yes或者no区别
# daemonize:yes:redis采用的是单进程多线程的模式。当redis.conf中选项daemonize设置成yes时，代表开启守护进程模式。在该模式下，            redis会在后台运行，并将进程pid号写入至redis.conf选项pidfile设置的文件中，此时redis将一直运行，除非手动kill该进程。
# daemonize:no: 当daemonize选项设置成no时，当前界面将进入redis的命令行界面，exit强制退出或者关闭连接工具(putty,xshell等)都会# 导致redis进程退出。

pidfile /var/run/redis_6379.pid # 如果以守护进程方式运行，那么久需要一个pid文件

# 日志
# Specify the server verbosity level.
# This can be one of:
# debug (a lot of information, useful for development/testing)
# verbose (many rarely useful info, but not a mess like the debug level)
# notice (moderately verbose, what you want in production probably) 生产环境适用
# warning (only very important / critical messages are logged)
loglevel notice

logfile "" # 日志文件未知名
databases 16 # 数据库的数量，默认是16个
```

> 快照

在规定的时间内，执行了多少次操作，则会持久化到文件 .rdb .aof

redis是内存数据库，如果没有持久化， 那么数据断电及失。

```shell
save 900 1 # 如果900s内，如果至少有一个key进行了修改，那么就进行持久化操作
save 300 10 # 如果300s内，如果至少有10个key进行了修改，那么就进行持久化操作
save 60 10000 # 如果60s内，如果至少有1000 0个key进行了修改，那么就进行持久化操作

stop-writes-on-bgsave-error yes # 持久化如果出错，是否还需要持续工作
rdbcompression yes # 是否压缩rdb文件，需要消耗cpu资源
rdbchecksum yes # 保存rdb文件的时候，进行错误校验
dir ./ # rdb文件保存目录
dbfilename dump.rdb # rdb保存文件名

```

> 复制 REPLICATION 

```shell
replicaof <masterip> <masterport> 配置从机 
```



> 安全

```shell
127.0.0.1:6379> config get requirepass # 获取redis的密码
1) "requirepass"
2) "" 
127.0.0.1:6379> config set requirepass "123456" # 设置密码
127.0.0.1:6379> auth 123456 # 使用密码登录
ok
```

> 限制 

```shell
maxclients 10000 # 设置redis的最大连接数
maxmemory <bytes> # 默认占用内存
maxmemory-policy noeviction # 内存达到上限之后的处理策略 

# redis.conf中的默认的过期策略是 volatile-lru
# maxmemory-policy 六种方式
# 1、volatile-lru：只对设置了过期时间的key进行LRU（默认值） 

# 2、allkeys-lru ： 删除lru算法的key   

# 3、volatile-random：随机删除即将过期key   

# 4、allkeys-random：随机删除   

# 5、volatile-ttl ： 删除即将过期的   

# 6、noeviction ： 永不过期，返回错误
```

> APPEND ONLY MODE 

```shell
appendonly no # 默认是不开启aof,默认使用rdb方式持久化，在大部分情况下，rdb完全够用。
appendfilename "appendonly.aof" # aof 持久化文件名
# appendfsync always # 每次修改都会写入，消耗性能
appendfsync everysec # 每秒执行一次
# appendfsync no # 不执行同步 
```

### redis持久化

#### RDB

rdb保存文件名是 dump.rdb

redis会单独fork一个子进程来进行持久化，先将数据写入到一个临时文件中，等持久化过程结束，再用这个临时文件替换上次持久化好的文件。整个过程中，主进程是不进行任何io操作的。这样就确保了极高的性能。

优点:如 果需要进行大规模数据的回复，且对数据回复的完整性要求不高，那么rdb比aof更高效

缺点：最后一次持久化后的数据可能丢失。

触发机制：

-  Save 命令执行一个同步保存操作，将当前 Redis 实例的所有数据快照(snapshot)以 RDB 文件的形式保存到硬盘。
- Flushall 
- 满足配置文件的save规则
- 退出redis，也会产生rdb文件 

#### AOF

默认是不开启的，需要手动配置。只要把”appendonly“改为”yes“

Aof 保存文件名是 appendonly.aof

以日志的形式来记录每个写操作，将redis的执行过的所有写执行记录下来，只许追加文件，不可以改写文件。

redis启动时会读取该文件重新构建数据。

优点：

​	文件的完成性更好 

缺点

​	aof文件远大于rdb文件，修复速度慢

​    aof运行效率低

### 主从复制

#### 环境配置

住需配置从库，不用配置主库

```shell
127.0.0.1:6379> info replication
# Replication
role:master # 角色
connected_slaves:0 # 从机个数
master_replid:f4ea2452b9bbd8a31320905af80703614402f39f
master_replid2:0000000000000000000000000000000000000000
master_repl_offset:0
second_repl_offset:-1
repl_backlog_active:0
repl_backlog_size:1048576
repl_backlog_first_byte_offset:0
repl_backlog_histlen:0
```

#### 复制原理

slave启动成功连接到master后会发送一个sync同步命令。

master接到命令后，启动后台的存盘进程，同时手机所有接收到的用于修改数据集的命令，在后台进程执行完毕后，master将传送数据到整个数据文件的slave，并完成一次完全同步。

全量复制：slave服务在接口道数据文件后，将其存盘并加载到内存中

增量复制：master继续将新收集到的修改命令依次传给slave，完成同步。

####  层层链路

上一个M连接下一个S。

### 哨兵模式

（自动选举老大的模式） 

#### 概述

哨兵模式是一种特殊的主从模式，首先redis提供了哨兵的命令，哨兵是一个独立的进程，独立运行。**原理是哨兵通过发送命令，等待redis服务器响应，从而监控运行的多个redis实例。如果主机发生故障，根据投票数自动将从库转换为主库。**

![image-20210212143033363](/Users/xinggaojian/Library/Application Support/typora-user-images/image-20210212143033363.png)

###  缓存穿透和雪崩

#### 缓存穿透

##### 概念

缓存中没有找到数据，请求频繁打到数据库。

##### 解决方案

###### 布隆过滤器

布隆数据库是一种数据结构，对所有可能查询的参数以hash方式存储，在控制层先进行校验，不符合规则就丢弃，从而避免了对底层存储系统的查询压力。

###### 缓存空对象

当缓存未命中，就返回一个空对象缓存起来，同时设置个过期时间，之后再访问这个数据就会走缓存，保护了后端数据源。

问题：

- 会有很多空的键值
- 对数据一致性有影响

#### 缓存击穿（量太大，缓存过期）

##### 概念

和缓存穿透的区别是，缓存击穿是指一个key非常热点，当这个key失效瞬间，持续的大并发直接打到数据库，会导致数据库瞬间压力过大。

##### 解决方案

- 设置热点数据用不过期
- 加互斥锁，保证只有一个进程链接到了数据库

#### 缓存雪崩

##### 概念

在某个时间段，缓存集中过期。

##### 解决方案

- redis高可用，异地多活
- 限流降级
- 数据预热



## Q&A

### **reidis为什么单线程还这么快？**

 核心：redis是将所有数据全部放在内存中的，所以说使用单线程去操作效率就是最高的（多线程有cpu的上下文切换，耗时！！）

### Redis批量删除key

redis本身不提供批量删除key的功能的，所以需要借用linux的管道xargs命令来删除。

```shell
redis-cli keys c:rel_user:* |xargs -t redis-cli del
```

redis-cli keys c:rel_user:* 把前面的key都查询数组出来，批量赋值给后面都 redis-cli del进行操作。

-t是输出内容。

# GO

## 1.基本语法

###  GMP 模型

> 含义

- M结构是Machine，系统线程，它由操作系统管理，goroutine就是跑在M之上的；M是一个很大的结构，里面维护小对象内存cache（mcache）、当前执行的goroutine、随机数发生器等等非常多的信息

- P结构是Processor，处理器，它的主要用途就是用来执行goroutine，它维护了一个goroutine队列，即runqueue。Processor的让我们从N:1调度到M:N调度的重要部分。

- G是goroutine实现的核心结构，它包含了栈，指令指针，以及其他对调度goroutine很重要的信息，例如其阻塞的channel。

  

### 面试题

> make和new的区别

make 被用来分配引用类型的内存： map, slice, channel，不会初始化零值，返回引用类型本身

new 被用来分配除了引用类型的所有其他类型的内存： int, string, struct等,并将其设置为零值，返回指针

> 引用类型有哪些

slice map channel interface

> 线程模型有几种

一对一模型(java)

多对一模型

多对多模型（go）

> GO反射通过字符串调用方法

```go
package main

import (
	"fmt"
	"reflect"
)

type Animal struct {
}

func (a *Animal)Eat()  {
	fmt.Print("EAT")
}

func main() {
	of := reflect.ValueOf(&Animal{})
	name := of.MethodByName("Eat")
	name.Call([]reflect.Value{})
}
```

> #### 值传递 vs 引用传递

传值会拷贝整个对象，而传指针只会拷贝指针地址，指向的对象是同一个。传指针可以减少值的拷贝，但是会导致内存分配逃逸到堆中，增加垃圾回收(GC)的负担。在对象频繁创建和删除的场景下，传递指针导致的 GC 开销可能会严重影响性能。

一般情况下，对于需要修改原对象值，或占用内存比较大的结构体，选择传指针。对于只读的占用内存较小的结构体，直接传值能够获得更好的性能

> GO锁的两种模式

正常模式

饥饿模式

> 哪些panic不能被recover

1. 数据竞争（比如：对map进行并发读写），可以通过golang的编译标记race对代码进行检测是否存在数据竞争（比如：并发读写map）
2. 内存不足
3. 死锁

### 
=======
> Mutex：4种易错场景大盘点

1. Lock/Unlock 不是成对出现,Unlock 一个未加锁的 Mutex 而导致 panic
2. Copy 已使用的 Mutex
3. 重入锁 (Mutex 不是可重入的锁。

```
当一个线程获取锁时，如果没有其它线程拥有这个锁，那么，这个线程就成功获取到这个锁。之后，如果其它线程再请求这个锁，就会处于阻塞等待的状态。但是，如果拥有这把锁的线程再请求这把锁的话，不会阻塞，而是成功返回，所以叫可重入锁（有时候也叫做递归锁）。只要你拥有这把锁，你可以可着劲儿地调用，比如通过递归实现一些算法，调用者不会阻塞或者死锁。
```

```go
// GO 实现可重入锁
// 方案一，通过goid
// RecursiveMutex 包装一个Mutex,实现可重入
type RecursiveMutex struct {
    sync.Mutex
    owner     int64 // 当前持有锁的goroutine id
    recursion int32 // 这个goroutine 重入的次数
}

func (m *RecursiveMutex) Lock() {
    gid := goid.Get()
    // 如果当前持有锁的goroutine就是这次调用的goroutine,说明是重入
    if atomic.LoadInt64(&m.owner) == gid {
        m.recursion++
        return
    }
    m.Mutex.Lock()
    // 获得锁的goroutine第一次调用，记录下它的goroutine id,调用次数加1
    atomic.StoreInt64(&m.owner, gid)
    m.recursion = 1
}

func (m *RecursiveMutex) Unlock() {
    gid := goid.Get()
    // 非持有锁的goroutine尝试释放锁，错误的使用
    if atomic.LoadInt64(&m.owner) != gid {
        panic(fmt.Sprintf("wrong the owner(%d): %d!", m.owner, gid))
    }
    // 调用次数减1
    m.recursion--
    if m.recursion != 0 { // 如果这个goroutine还没有完全释放，则直接返回
        return
    }
    // 此goroutine最后一次调用，需要释放锁
    atomic.StoreInt64(&m.owner, -1)
    m.Mutex.Unlock()
}

// 方案二 token
// Token方式的递归锁
type TokenRecursiveMutex struct {
    sync.Mutex
    token     int64
    recursion int32
}

// 请求锁，需要传入token
func (m *TokenRecursiveMutex) Lock(token int64) {
    if atomic.LoadInt64(&m.token) == token { //如果传入的token和持有锁的token一致，说明是递归调用
        m.recursion++
        return
    }
    m.Mutex.Lock() // 传入的token不一致，说明不是递归调用
    // 抢到锁之后记录这个token
    atomic.StoreInt64(&m.token, token)
    m.recursion = 1
}

// 释放锁
func (m *TokenRecursiveMutex) Unlock(token int64) {
    if atomic.LoadInt64(&m.token) != token { // 释放其它token持有的锁
        panic(fmt.Sprintf("wrong the owner(%d): %d!", m.token, token))
    }
    m.recursion-- // 当前持有这个锁的token释放锁
    if m.recursion != 0 { // 还没有回退到最初的递归调用
        return
    }
    atomic.StoreInt64(&m.token, 0) // 没有递归调用了，释放锁
    m.Mutex.Unlock()
}

```

4.死锁

```go

package main


import (
    "fmt"
    "sync"
    "time"
)


func main() {
    // 派出所证明
    var psCertificate sync.Mutex
    // 物业证明
    var propertyCertificate sync.Mutex


    var wg sync.WaitGroup
    wg.Add(2) // 需要派出所和物业都处理


    // 派出所处理goroutine
    go func() {
        defer wg.Done() // 派出所处理完成


        psCertificate.Lock()
        defer psCertificate.Unlock()


        // 检查材料
        time.Sleep(5 * time.Second)
        // 请求物业的证明
        propertyCertificate.Lock()
        propertyCertificate.Unlock()
    }()


    // 物业处理goroutine
    go func() {
        defer wg.Done() // 物业处理完成


        propertyCertificate.Lock()
        defer propertyCertificate.Unlock()


        // 检查材料
        time.Sleep(5 * time.Second)
        // 请求派出所的证明
        psCertificate.Lock()
        psCertificate.Unlock()
    }()


    wg.Wait()
    fmt.Println("成功完成")
}
```





## 2.并发

> 协程控制并发

```go

func main() {
	var ch = make(chan struct{},3)
	var wg sync.WaitGroup
	for i:=0;i<100;i++ {
		ch <- struct{}{}
		wg.Add(1)
		go func(i int) {
			defer wg.Done()
			log.Println("do someting",i)
			time.Sleep(time.Second)
			<-ch
		}(i)
	}
	wg.Wait()
}
```



## 3.包用法

#### 常用的包有哪些

Sync,strings,time,reflect,regexp,io

#### benchmark 基准测试

- benchmark 和普通的单元测试用例一样，都位于 `_test.go` 文件中。

- 函数名以 `Benchmark` 开头，参数是 `b *testing.B`。和普通的单元测试用例很像，单元测试函数名以 `Test` 开头，参数是 `t *testing.T`。

- `go test <module name>/<package name>` 用来运行某个 package 内的所有测试用例。

- go test 命令默认不运行 benchmark 用例的，如果我们想运行 benchmark 用例，则需要加上 -bench

- 对于性能测试来说，提升测试准确度的一个重要手段就是增加测试的次数。我们可以使用 `-benchtime` 和 `-count` 两个参数达到这个目的。

- `-benchmem` 参数可以度量内存分配的次数。

-  `-cpuprofile` 参数即可生成 `BenchmarkFib` 对应的 CPU profile 文件

  

```go
// fib.go
package main

func fib(n int) int {
	if n == 0 || n == 1 {
		return n
	}
	return fib(n-2) + fib(n-1)
}
```

```go
// fib_test.go
package main

import "testing"

func BenchmarkFib(b *testing.B) {
	for n := 0; n < b.N; n++ {
		fib(30) // run fib(30) b.N times
	}
}
```

#### Pprof性能测试

```go
import (
	"runtime/pprof"
)

func main() {
	f, _ := os.OpenFile("cpu.pprof", os.O_CREATE|os.O_RDWR, 0644)
	defer f.Close()
	pprof.StartCPUProfile(f)   // 度量这个应用程序的 CPU 性能数据
	defer pprof.StopCPUProfile()
	n := 10
	for i := 0; i < 5; i++ {
		nums := generate(n)
		bubbleSort(nums)
		n *= 10
	}
}
```

#### stringBuilder

```go
func builderConcat(n int, str string) string {
   var builder strings.Builder
   builder.Grow(n * len(str))
   for i := 0; i < n; i++ {
      builder.WriteString(str)
   }
   return builder.String()
}
```



## 4.框架

### 4.1beego

### 4.2gin

## 5.微服务

# LINUX

## 面试题

> ### 进程、线程、协程区别

#### 进程

进程是一个程序在一个数据集中的一次动态执行过程，可以简单理解为“正在执行的程序”，它是CPU 资源分配和调度的独立单位

#### 线程

线程是在进程之后发展出来的概念。 线程也叫轻量级进程，它是一个基本的 CPU 执行单元，也是程序执行过程中的最小单元，由线程 ID、程序计数器、寄存器集合和堆栈共同组成。一个进程可以包含多个线程

#### 协程

协程是一种用户态的轻量级线程，又称微线程，英文名 Coroutine，协程的调度完全由用户控制

> 进程间如何通信

- 管道

管道是进程间通信最简单的方式，任何进程的标准输出都可以作为其他进程的输入。

- 信号

信号是进程间通信的其中一种方法，当然也可以是内核给进程发送的消息，注意信息只是告诉进程发生了什么事件，而不会传递任何数据。

- 消息队列

和传统消息队列类似，但是在内核实现的。

- 共享内存
- 信号量

信号量本质上是一个整型计数器，调用`wait`时计数减一，减到零开始阻塞进程，从而达到进程、线程间协作的作用

- 套接口

也就是通过网络来通信，这也是最通用的IPC，不要求进程在同一台服务器上。

## SED

```shell
 sed -i 's/www.zhiwangcnki.com/jz.gitlay.com/g' `grep  -rl www.zhiwangcnki.com html`
```

## AWK

### 循环统计

```shell
cat 192.164.58.*/access_log.20201224*|grep -i 'physician' |grep 'unix:'|awk '{print $(NF-6)}'|awk '{a[$0]+=1} END {for(i in a){print a[i],i}}'|sort -n

```

### 判断时间

```shell
cat 192.164.58.*/china-gov-app.log.2021022017*|grep 'yiqingtongxing/districtinquiries'| awk '$3 >= "16:50:00" && $3 <= "17:20:00"'|wc -l
```



## GREP

## XARFS

批量杀死进程

```shell
ps aux | grep php | awk '{print $2}' | xargs kill -9
```

批量删除redis key

```shell
redis-cli keys "mailspec*" | xargs del
eg:
批量删除em开头的key
redis-cli -h 192.169.1.71 -p 7001 -a 123456 keys em* | xargs -r -t -n1 ./redis-cli -h 192.169.1.71 -p 7001 -a 123456 del

```





# NGINX

## 负载均衡

### 几种方式？

#### 轮询

```nginx
upstream  backserver {
       server    localhost:10001;
       server    localhost:10002;
}
```

#### 权重

```nginx
upstream  backserver {
       server    localhost:10001 weight=1;
       server    localhost:10002 weight=2;
}
```

####  iphash

```nginx
#每个请求按访问ip的hash结果分配，这样每个访客固定访问一个后端服务器，可以解决session的问题。 
upstream backserver { 
  ip_hash; 
  server 192.168.0.14:88; 
  server 192.168.0.15:80; 
} 
```

### 什么是hash一致性算法？

# 其他

## 1.设计模式

[https://www.cnblogs.com/yuanwanli/p/8796402.html]: 设计模式

> 单例模式

```go
type singleton struct{}
2 var ins *singleton
3 var once sync.Once
4 func GetIns() *singleton {
5     once.Do(func(){
6         ins = &singleton{}
7     })
8     return ins
9 }
```



```php
<?php
class Singleton{
    //私有属性，用于保存实例
    private static $instance;
    //构造方法私有化，防止外部创建实例
    private function __construct(){}
    //公有方法，用于获取实例
    public static function getInstance(){
        //判断实例有无创建，没有的话创建实例并返回，有的话直接返回
        if(!(self::$instance instanceof self)){
            self::$instance = new self();
        }
        return self::$instance;
    }
    //克隆方法私有化，防止复制实例
    private function __clone(){}

}

```

> 工厂模式

> 观察者模式

1：观察者模式(Observer)，当一个对象状态发生变化时，依赖它的对象全部会收到通知，并自动更新。 
2：场景:一个事件发生后，要执行一连串更新操作。传统的编程方式，就是在事件的代码之后直接加入处理的逻辑。当更新的逻辑增多之后，代码会变得难以维护。这种方式是耦合的，侵入式的，增加新的逻辑需要修改事件的主体代码。 
3：观察者模式实现了低耦合，非侵入式的通知与更新机制。 

> 策略模式

策略模式，将一组特定的行为和算法封装成类，以适应某些特定的上下文环境。 
eg：假如有一个电商网站系统，针对男性女性用户要各自跳转到不同的商品类目，并且所有的广告位展示不同的广告。在传统的代码中，都是在系统中加入各种if else的判断，硬编码的方式。如果有一天增加了一种用户，就需要改写代码。使用策略模式，如果新增加一种用户类型，只需要增加一种策略就可以。其他所有的地方只需要使用不同的策略就可以。 
首先声明策略的接口文件，约定了策略的包含的行为。然后，定义各个具体的策略实现类。

> 适配器模式

将各种截然不同的函数接口封装成统一的API。 
PHP中的数据库操作有MySQL,MySQLi,PDO三种，可以用适配器模式统一成一致，使不同的数据库操作，统一成一样的API。类似的场景还有cache适配器，可以将memcache,redis,file,apc等不同的缓存函数，统一成一致。 
首先定义一个接口(有几个方法，以及相应的参数)。然后，有几种不同的情况，就写几个类实现该接口。将完成相似功能的函数，统一成一致的方法。

> 注册树模式

注册模式，解决全局共享和交换对象。已经创建好的对象，挂在到某个全局可以使用的数组上，在需要使用的时候，直接从该数组上获取即可。将对象注册到全局的树上。任何地方直接去访问。

```php
<?php

class Register
{
    protected static  $objects;
    function set($alias,$object)//将对象注册到全局的树上
    {
        self::$objects[$alias]=$object;//将对象放到树上
    }
    static function get($name){
        return self::$objects[$name];//获取某个注册到树上的对象
    }
    function _unset($alias)
    {
        unset(self::$objects[$alias]);//移除某个注册到树上的对象。
    }
}
```





## 2.GIT

### 2.1 GIT配置

#### 2.1.1 配置User信息

```shell
git config --global user.name 'your_name'
git config --global user.email 'your_email'
```

#### 2.1.2 config的三个作用于

```shell
git config --local #local只对某个仓库有效
git config --global #global对当前用户所有仓库有效
git config --system #system对系统所有登录的用户有效
```

#### 2.1.3 小时config的配置，加--list

```shell
git config --list --local
git config --list --global
git config --list --system
```

### 2.2 给文件重命名

```shell
git mv old_name new_name
```

2.3 通过git log 查看版本历史

2.4 cherry pick 命令的作用，就是将指定的提交（commit）应用于其他分支。

```bash
$ git cherry-pick <commitHash>
```

## 网络基础

### 五层模型

#### 应用层

负责应用程序间沟通，如简单电子邮件传输（SMTP）、文件传输协议（FTP）、网络远程访问协议（Telnet）等. 我们的网络编程主要就是针对应用层.

#### 传输层

负责两台主机之间的数据传输. 如传输控制协议 (TCP), 能够确保数据可靠的从源主机发送到目标主机.

#### 网络层

负责地址管理和路由选择. 例如在IP协议中, 通过IP地址来标识一台主机, 并通过路由表的方式规划出两台主机之间的数据传输的线路(路由). 路由器(Router)工作在网路层.

#### 数据层

负责设备之间的数据帧的传送和识别. 例如网卡设备的驱动、帧同步(就是说从网线上检测到什么信号算作新帧的开始)、冲突检测(如果检测到冲突就自动重发)、数据差错校验等工作. 有以太网、令牌环网, 无线LAN等标准. 交换机(Switch)工作在数据链路层.

#### 物理层

负责光/电信号的传递方式. 比如现在以太网通用的网线(双绞 线)、早期以太网采用的的同轴电缆(现在主要用于有线电视)、光纤, 现在的wifi无线网使用电磁波等都属于物理层的概念。物理层的能力决定了最大传输速率、传输距离、抗干扰性等. 集线器(Hub)工作在物理层.

### TCP 和 UDP区别

|              | UDP                                        | TCP                                    |
| :----------- | :----------------------------------------- | :------------------------------------- |
| 是否连接     | 无连接                                     | 面向连接                               |
| 是否可靠     | 不可靠传输，不使用流量控制和拥塞控制       | 可靠传输，使用流量控制和拥塞控制       |
| 连接对象个数 | 支持一对一，一对多，多对一和多对多交互通信 | 只能是一对一通信                       |
| 传输方式     | 面向报文                                   | 面向字节流                             |
| 首部开销     | 首部开销小，仅8字节                        | 首部最小20字节，最大60字节             |
| 适用场景     | 适用于实时应用（IP电话、视频会议、直播等） | 适用于要求可靠传输的应用，例如文件传输 |

### 浏览器打开一个网站经历了哪些步骤

1. Chrome搜索自身的DNS缓存

2. 搜索操作系统自身的DNS缓存（浏览器没有找到缓存或缓存已经失效）
   查看Chrome浏览器的DNS缓存信息

3. 读取本地HOST文件

4. 浏览器发起一个DNS的一个系统调用

5. - 运营商服务器把结果返回操作系统内核同时缓存起来
   - 操作系统内核把结果返回浏览器
   - 最终浏览器拿到www.jianshu.com对应的IP地址

6. - 宽带运营商服务器查看本身缓存
   - 运营商服务器发起一个迭代DNS解析的请求

7. 浏览器获得域名对应的IP地址后，发起HTTP“三次握手”

8. TCP/IP连接建立起来后，浏览器就可以向服务器发送HTTP请求了。（使用了比如说，用HTTP的GET方法请求一个跟域名，协议可以采用HTTP1.0。）

9. 服务器端接受到了这个请求，根据路径参数，经过后端的一些处理之后，把处理后的一个结果的数据返回给浏览器。如果是慕课网的页面就会把完整的HTML页面代码返回给浏览器。

10. 浏览器拿到了简书网的完整的HTML页面代码，在解析和渲染这个页面的时候，里面的JS、CSS、图片静态资源，他们同样也是一个个HTTP请求都需要经过上面的主要的七个步骤。

11. 浏览器根据拿到的资源对页面进行渲染，最终把一个完整的页面呈现给了用户

### 三次握手

1. 第一次握手：建立连接时，客户端发送syn包（syn=j）到服务器，并进入SYN_SENT状态，等待服务器确认；SYN：同步序列编号（Synchronize Sequence Numbers）。
2. 第二次握手：服务器收到syn包，必须确认客户的SYN（ack=j+1），同时自己也发送一个SYN包（syn=k），即SYN+ACK包，此时服务器进入SYN_RECV状态；
3. 第三次握手：客户端收到服务器的SYN+ACK包，向服务器发送确认包ACK(ack=k+1），此包发送完毕，客户端和服务器进入ESTABLISHED（TCP连接成功）状态，完成三次握手。



### 四次挥手

1、第一次挥手：客户端发送一个 FIN 报文，报文中会指定一个序列号。此时客户端处于**CLOSED_WAIT1**状态。

2、第二次握手：服务端收到 FIN 之后，会发送 ACK 报文，且把客户端的序列号值 + 1 作为 ACK 报文的序列号值，表明已经收到客户端的报文了，此时服务端处于 **CLOSE_WAIT2**状态。

3、第三次挥手：如果服务端也想断开连接了，和客户端的第一次挥手一样，发给 FIN 报文，且指定一个序列号。此时服务端处于 **LAST_ACK** 的状态。

4、第四次挥手：客户端收到 FIN 之后，一样发送一个 ACK 报文作为应答，且把服务端的序列号值 + 1 作为自己 ACK 报文的序列号值，此时客户端处于 **TIME_WAIT** 状态。需要过一阵子以确保服务端收到自己的 ACK 报文之后才会进入 CLOSED 状态

5、服务端收到 ACK 报文之后，就处于关闭连接了，处于 CLOSED 状态。

### IME_WAIT

为什么客户端发送 ACK 之后不直接关闭，而是要等一阵子才关闭。这其中的原因就是，要确保服务器是否已经收到了我们的 ACK 报文，如果没有收到的话，服务器会重新发 FIN 报文给客户端，客户端再次收到 ACK 报文之后，就知道之前的 ACK 报文丢失了，然后再次发送 ACK 报文。

## [单点登录实现](https://www.jianshu.com/p/2afdc5aa282b)

> 登录

1. 登录系统1，发现未登录，跳转sso（系统1地址）
2. sso未登录，跳转登录页面，登录后，跳转至系统1（带着令牌），同时存储 另外与系统1的映射关系
3. 系统1拿着令牌令牌去sso校验，如果有存储，验证成功，系统1登录成功

> 注销

1. 用户向系统1发起注销请求
2. 系统1根据用户与系统1建立的会话id拿到令牌，向sso认证中心发起注销请求
3. sso认证中心校验令牌有效，销毁全局会话，同时取出所有用此令牌注册的系统地址
4. sso认证中心向所有注册系统发起注销请求
5. 各注册系统接收sso认证中心的注销请求，销毁局部会话
6. sso认证中心引导用户至登录页面


## 令牌桶限流

令牌桶算法的原理是系统以恒定的速率产生令牌，然后把令牌放到令牌桶中，令牌桶有一个容量，当令牌桶满了的时候，再向其中放令牌，那么多余的令牌会被丢弃；当想要处理一个请求的时候，需要从令牌桶中取出一个令牌，如果此时令牌桶中没有令牌，那么则拒绝该请求。

布隆过滤器
=======


## 计算机基础

### 进制转换

#### 二进制转十进制

```txt
方法：二进制数从低位到高位（即从右往左）计算，第0位的权值是2的0次方，第1位的权值是2的1次方，第2位的权值是2的2次方，依次递增下去，把最后的结果相加的值就是十进制的值了。

　　例：将二进制的(101011)B转换为十进制的步骤如下：

1. 第0位 1 x 2^0 = 1；

2. 第1位 1 x 2^1 = 2；

3. 第2位 0 x 2^2 = 0；

4. 第3位 1 x 2^3 = 8；

5. 第4位 0 x 2^4 = 0；

6. 第5位 1 x 2^5 = 32；

7. 读数，把结果值相加，1+2+0+8+0+32=43，即(101011)B=(43)D。
```

#### 十进制转二进制

```txt
方法：除2取余法，即每次将整数部分除以2，余数为该位权上的数，而商继续除以2，余数又为上一个位权上的数，这个步骤一直持续下去，直到商为0为止，最后读数时候，从最后一个余数读起，一直到最前面的一个余数。 

　　例：将十进制的(43)D转换为二进制的步骤如下：

\1. 将商43除以2，商21余数为1；

\2. 将商21除以2，商10余数为1；

\3. 将商10除以2，商5余数为0；

\4. 将商5除以2，商2余数为1；

\5. 将商2除以2，商1余数为0； 

\6. 将商1除以2，商0余数为1； 

\7. 读数，因为最后一位是经过多次除以2才得到的，因此它是最高位，读数字从最后的余数向前读，101011，即

(43)D=(101011)B。
```

[![wpsC02F.tmp](https://images0.cnblogs.com/blog/48305/201501/191446019539875.png)](https://images0.cnblogs.com/blog/48305/201501/191446012199718.png)